from crewai import Task


def create_testing_task(agent, project_dir: str, project_type: str, context_tasks: list = None):
    return Task(
         description=f"""Test, validate, and quality-assure the implemented project:

         PROJECT DIRECTORY: {project_dir}
         PROJECT TYPE: {project_type}
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         YOUR QUALITY ASSURANCE RESPONSIBILITIES:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         ğŸ” PHASE 1: COMPREHENSIVE CODE REVIEW
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         1. Review ALL source code files for quality and correctness:
            
            Syntax & Compilation:
            â–¡ Check for syntax errors using language-specific validators
            â–¡ Verify code compiles/transpiles without errors
            â–¡ Ensure all imports/includes are valid and available
            â–¡ Check for undefined variables or functions
            â–¡ Verify type safety (TypeScript, typed Python, Java, C#, Go, Rust)
            
            Code Structure & Organization:
            â–¡ Verify proper file and directory organization
            â–¡ Check module/package structure follows conventions
            â–¡ Ensure separation of concerns (business logic, data access, UI)
            â–¡ Verify appropriate use of design patterns
            â–¡ Check for proper layering (presentation, business, data)
            
            Logic & Correctness:
            â–¡ Review algorithms for correctness
            â–¡ Check for logical errors and edge cases
            â–¡ Verify mathematical calculations
            â–¡ Review conditional logic (if/else, switch statements)
            â–¡ Check loop conditions and termination
            â–¡ Verify state management and transitions
            â–¡ Review async/concurrent operations for race conditions
            
            Best Practices Compliance:
            â–¡ Verify adherence to language-specific idioms
            â–¡ Check SOLID principles application
            â–¡ Ensure DRY (Don't Repeat Yourself) principle
            â–¡ Verify proper abstraction levels
            â–¡ Check for appropriate use of inheritance vs composition
            â–¡ Review dependency injection usage
            â–¡ Verify proper interface/contract definitions
            
            Code Quality Metrics:
            â–¡ Function/method length (should be < 50-75 lines)
            â–¡ Class size (should be < 300 lines)
            â–¡ Cyclomatic complexity (should be < 10 per function)
            â–¡ Nesting depth (should be < 4 levels)
            â–¡ Code duplication (identify repeated code blocks)
            â–¡ Naming conventions (descriptive, not generic)
            
            Error Handling:
            â–¡ Verify comprehensive error handling throughout
            â–¡ Check appropriate exception types are used
            â–¡ Ensure helpful error messages with context
            â–¡ Verify proper resource cleanup (try/finally, using, defer)
            â–¡ Check for bare except/catch blocks
            â–¡ Verify errors are logged appropriately
            
            Security Review:
            â–¡ Check input validation and sanitization
            â–¡ Verify no hardcoded credentials or secrets
            â–¡ Review SQL queries for injection vulnerabilities
            â–¡ Check XSS prevention in web apps
            â–¡ Verify CSRF protection in web apps
            â–¡ Review authentication and authorization logic
            â–¡ Check for insecure deserialization
            â–¡ Verify secure random number generation
            â–¡ Review cryptographic implementations
            
            Documentation:
            â–¡ Verify all public APIs have documentation
            â–¡ Check docstrings/JSDoc/Javadoc are comprehensive
            â–¡ Ensure complex logic has inline comments
            â–¡ Verify usage examples in documentation
            â–¡ Check README completeness and accuracy
            
            Resource Management:
            â–¡ Verify proper memory management
            â–¡ Check for memory leaks (unreleased resources)
            â–¡ Review file handle management
            â–¡ Check database connection handling
            â–¡ Verify proper thread/goroutine cleanup
            â–¡ Review network connection management

         ğŸ§ª PHASE 2: COMPREHENSIVE TEST SUITE CREATION
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         2. Create thorough test files covering all scenarios:

            A. UNIT TESTS (Test individual functions/methods/classes):
            
            For EACH function/method, create tests for:
            â–¡ Happy path: Valid inputs produce expected outputs
            â–¡ Empty inputs: Empty strings, empty arrays, null/nil/None
            â–¡ Invalid types: Wrong type inputs (string vs number, etc.)
            â–¡ Boundary values: Min, max, zero, negative values
            â–¡ Edge cases: Very large inputs, unicode characters, special chars
            â–¡ Default parameters: Test with and without optional arguments
            â–¡ Exception cases: Invalid inputs raise appropriate errors
            â–¡ State changes: Verify object state after operations (for stateful classes)
            
            For EACH class, create tests for:
            â–¡ Initialization: Valid and invalid constructor parameters
            â–¡ All public methods: Test complete public API
            â–¡ State management: Verify state transitions
            â–¡ Resource cleanup: Test destructors/disposal methods
            â–¡ Thread safety: Test concurrent access (if applicable)
            
            Test Structure by Language:
            
            Python (pytest):
            - tests/test_<module>.py for each module
            - Use fixtures for reusable test data
            - Use @pytest.mark.parametrize for multiple scenarios
            - Use pytest.raises for exception testing
            - Mock external dependencies with unittest.mock
            
            JavaScript/TypeScript (Jest/Mocha/Vitest):
            - __tests__/<module>.test.js/ts for each module
            - Use describe/it blocks for organization
            - Use beforeEach/afterEach for setup/teardown
            - Use jest.mock() for mocking
            - Use test.each() for parameterized tests
            
            Java (JUnit):
            - src/test/java matching package structure
            - Use @Test, @BeforeEach, @AfterEach annotations
            - Use @ParameterizedTest for multiple scenarios
            - Use Mockito for mocking
            - Use AssertJ for fluent assertions
            
            C# (xUnit/NUnit):
            - Separate test project
            - Use [Fact] and [Theory] attributes
            - Use xUnit fixtures or NUnit SetUp/TearDown
            - Use Moq for mocking
            - Use FluentAssertions
            
            Go (testing package):
            - _test.go files alongside source
            - Use table-driven tests
            - Use t.Run() for subtests
            - Use testify/assert for assertions
            - Mock interfaces with generated mocks
            
            Rust (built-in testing):
            - #[cfg(test)] modules in source files
            - tests/ directory for integration tests
            - Use #[test] attribute
            - Use assert!, assert_eq! macros
            - Use mockall for mocking
            
            B. INTEGRATION TESTS (Test component interactions):
            
            â–¡ Module/component interactions
            â–¡ Database operations (with test database)
            â–¡ API endpoint testing (request/response validation)
            â–¡ File I/O operations (with temp files)
            â–¡ External service integrations (with mocks)
            â–¡ Message queue operations
            â–¡ Cache operations
            â–¡ Authentication flows
            â–¡ Multi-step workflows
            
            C. FUNCTIONAL/E2E TESTS (Test complete workflows):
            
            For Web Applications:
            â–¡ User registration and login flows
            â–¡ CRUD operations through UI
            â–¡ Form validation and submission
            â–¡ Navigation and routing
            â–¡ Session management
            â–¡ Browser compatibility (Chrome, Firefox, Safari, Edge)
            â–¡ Responsive design on different screen sizes
            
            For APIs:
            â–¡ All endpoint methods (GET, POST, PUT, DELETE, PATCH)
            â–¡ Request validation (required params, types, formats)
            â–¡ Response codes (200, 201, 400, 401, 403, 404, 500)
            â–¡ Response schemas and data validation
            â–¡ Authentication and authorization
            â–¡ Rate limiting
            â–¡ CORS headers
            
            For CLI Applications:
            â–¡ All commands with valid arguments
            â–¡ Help text and documentation
            â–¡ Error messages for invalid usage
            â–¡ Exit codes
            â–¡ Input/output redirection
            â–¡ Environment variable handling
            
            For Mobile Applications:
            â–¡ Screen navigation flows
            â–¡ Form inputs and validation
            â–¡ Offline functionality
            â–¡ Background/foreground transitions
            â–¡ Push notification handling
            â–¡ Deep linking
            â–¡ Different device sizes and orientations
            
            D. PERFORMANCE TESTS (if applicable):
            
            â–¡ Response time benchmarks
            â–¡ Load testing (concurrent users/requests)
            â–¡ Stress testing (breaking points)
            â–¡ Memory usage profiling
            â–¡ CPU usage monitoring
            â–¡ Database query performance
            â–¡ Large dataset handling
            
            E. SECURITY TESTS (if applicable):
            
            â–¡ SQL injection attempts
            â–¡ XSS attack prevention
            â–¡ CSRF token validation
            â–¡ Authentication bypass attempts
            â–¡ Authorization checks
            â–¡ Rate limiting enforcement
            â–¡ Input validation effectiveness
            â–¡ Session security

         ğŸ¯ PHASE 3: TEST EXECUTION & VALIDATION
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         3. Run comprehensive testing based on technology stack:

            Execute Tests:
            â–¡ Run unit tests: pytest / npm test / mvn test / dotnet test / go test / cargo test
            â–¡ Run integration tests with test databases/services
            â–¡ Run E2E tests (Selenium, Playwright, Cypress, Puppeteer)
            â–¡ Generate coverage reports (aim for 80%+ line coverage)
            â–¡ Check coverage gaps and add missing tests
            
            Test Results:
            â–¡ Verify 100% test pass rate (all tests must pass)
            â–¡ Document any test failures with details
            â–¡ Identify flaky tests (inconsistent results)
            â–¡ Measure test execution time
            â–¡ Check for test pollution (tests affecting each other)
            
            Coverage Analysis:
            â–¡ Line coverage: Percentage of code lines executed
            â–¡ Branch coverage: Percentage of decision branches taken
            â–¡ Function coverage: Percentage of functions called
            â–¡ Identify untested code paths
            â–¡ Prioritize critical path coverage

         âœ¨ PHASE 4: CODE FORMATTING & STYLE
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         4. Format and style check code using language-specific tools:

            Python:
            â–¡ Format with Black: black {project_dir}
            â–¡ Sort imports with isort: isort {project_dir}
            â–¡ Check with Flake8: flake8 {project_dir}
            â–¡ Type check with mypy: mypy {project_dir}
            
            JavaScript/TypeScript:
            â–¡ Format with Prettier: prettier --write .
            â–¡ Lint with ESLint: eslint src/
            â–¡ Type check TypeScript: tsc --noEmit
            
            Java:
            â–¡ Format with Google Java Format or Spotless
            â–¡ Check style with Checkstyle
            â–¡ Run SpotBugs for bug detection
            â–¡ Run PMD for code analysis
            
            C#:
            â–¡ Format with dotnet format
            â–¡ Run Roslyn analyzers
            â–¡ Check with StyleCop
            
            Go:
            â–¡ Format with go fmt
            â–¡ Run go vet for correctness
            â–¡ Lint with golangci-lint
            
            Rust:
            â–¡ Format with cargo fmt
            â–¡ Lint with cargo clippy
            
            Style Checks:
            â–¡ Line length compliance
            â–¡ Indentation consistency
            â–¡ Naming conventions
            â–¡ Import organization
            â–¡ Whitespace consistency
            â–¡ Comment formatting

         ğŸš€ PHASE 5: EXECUTION & FUNCTIONAL VERIFICATION
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         5. Execute and verify the application works correctly:

            Build Process:
            â–¡ Verify build completes without errors
            â–¡ Check for build warnings
            â–¡ Verify all dependencies resolve
            â–¡ Check build artifacts are generated correctly
            
            Execution Tests:
            
            For CLI Applications:
            â–¡ Run with --help flag to verify help text
            â–¡ Execute main commands with sample inputs
            â–¡ Test with valid and invalid arguments
            â–¡ Verify exit codes are appropriate
            â–¡ Check error messages are helpful
            
            For Web Applications:
            â–¡ Start development server successfully
            â–¡ Access home page and verify loading
            â–¡ Navigate through main routes
            â–¡ Test key user interactions
            â–¡ Check browser console for errors
            â–¡ Verify API responses
            
            For APIs/Services:
            â–¡ Start server successfully
            â–¡ Check health/status endpoint
            â–¡ Test main API endpoints with sample data
            â–¡ Verify response formats
            â–¡ Check logging output
            
            For Desktop Applications:
            â–¡ Launch application
            â–¡ Test main window/UI loads correctly
            â–¡ Verify menu items work
            â–¡ Test key features
            
            For Mobile Applications:
            â–¡ Build for target platform (iOS/Android)
            â–¡ Run in simulator/emulator
            â–¡ Test main screens and navigation
            â–¡ Verify no crashes on startup
            
            For Libraries/Packages:
            â–¡ Import/require in test script
            â–¡ Call main public APIs
            â–¡ Verify documented examples work
            â–¡ Check no runtime errors

         ğŸ”’ PHASE 6: SECURITY SCAN
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         6. Perform security analysis:

            Dependency Security:
            â–¡ Scan for known vulnerabilities:
            - Python: safety check / pip-audit
            - JavaScript: npm audit / yarn audit
            - Java: OWASP Dependency-Check
            - C#: dotnet list package --vulnerable
            - Go: nancy or govulncheck
            - Rust: cargo audit
            â–¡ Check for outdated dependencies
            â–¡ Verify no dependencies with critical CVEs
            
            Code Security:
            â–¡ Check for hardcoded secrets (credentials, API keys, tokens)
            â–¡ Verify environment variables are used for sensitive data
            â–¡ Review authentication implementations
            â–¡ Check authorization logic
            â–¡ Verify input validation and sanitization
            â–¡ Review cryptographic usage
            â–¡ Check for insecure random number generation
            â–¡ Verify secure communication (HTTPS/TLS)

         ğŸ“Š PHASE 7: PERFORMANCE ANALYSIS (if applicable)
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         7. Analyze performance characteristics:

            â–¡ Profile memory usage
            â–¡ Measure CPU utilization
            â–¡ Check response times
            â–¡ Analyze database query performance
            â–¡ Review algorithm efficiency
            â–¡ Identify bottlenecks
            â–¡ Check for N+1 query problems
            â–¡ Verify caching effectiveness
            â–¡ Test with large datasets
            â–¡ Measure startup time

         ğŸ“ PHASE 8: DOCUMENTATION VERIFICATION
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         8. Verify documentation completeness and accuracy:

            README.md:
            â–¡ Verify installation instructions work
            â–¡ Test all code examples provided
            â–¡ Check links are not broken
            â–¡ Verify screenshots/diagrams are present (if mentioned)
            â–¡ Check prerequisites are accurate
            â–¡ Verify configuration examples are correct
            
            API Documentation:
            â–¡ Check all endpoints are documented
            â–¡ Verify request/response examples are accurate
            â–¡ Test that examples actually work
            â–¡ Check parameter descriptions are clear
            
            Code Documentation:
            â–¡ Verify all public APIs have docstrings/comments
            â–¡ Check examples in docstrings are correct
            â–¡ Verify type annotations are accurate

         ğŸ“‹ PHASE 9: COMPREHENSIVE TEST REPORT
         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         9. Create detailed TEST_REPORT.md including:

            Report Structure:
            
            # Test Report - [Project Name]
            
            ## Executive Summary
            - Overall Status: âœ… PASS / âŒ FAIL / âš ï¸ PARTIAL
            - Test Coverage: XX%
            - Tests Executed: XX
            - Tests Passed: XX (XX%)
            - Tests Failed: XX (XX%)
            - Code Quality: Excellent / Good / Needs Improvement
            - Deployment Risk: LOW / MEDIUM / HIGH
            
            ## Test Coverage Report
            - Module/component coverage breakdown
            - Overall coverage percentage
            - Uncovered lines and why
            - Branch coverage statistics
            
            ## Test Results
            - Unit Tests: Detailed breakdown by module
            - Integration Tests: Results for each integration point
            - E2E Tests: Results for each workflow
            - Performance Tests: Benchmarks and measurements
            - Security Tests: Vulnerability findings
            
            ## Code Quality Analysis
            - Syntax Validation: Pass/Fail
            - Code Formatting: Issues found and fixed
            - Linting Results: Warnings and errors
            - Type Checking: Type errors found
            - Security Scan: Vulnerabilities discovered
            - Complexity Metrics: Functions exceeding thresholds
            
            ## Execution Tests
            - Build process results
            - Application startup results
            - Main feature testing results
            - Error handling verification
            
            ## Issues Found
            - ğŸ”´ Critical Issues: Must fix before deployment
            - ğŸŸ  Major Issues: Should fix soon
            - ğŸŸ¡ Minor Issues: Nice to fix
            - ğŸ”µ Suggestions: Future improvements
            
            ## Performance Analysis (if applicable)
            - Response time measurements
            - Memory usage statistics
            - CPU utilization data
            - Scalability assessment
            
            ## Security Assessment
            - Vulnerability scan results
            - Security best practices compliance
            - Risk areas identified
            
            ## Risk Assessment
            - Deployment readiness
            - Known issues and workarounds
            - Recommendations
            
            ## Recommendations
            - Immediate actions required
            - Future enhancements
            - Code refactoring suggestions
            - Performance optimization opportunities
            
            ## Test Environment
            - Operating System
            - Language/Runtime version
            - Test framework version
            - Dependency versions
            - Test duration
            
            ## Conclusion
            - Final verdict: âœ… APPROVED / âš ï¸ CONDITIONAL / âŒ REJECTED
            - Overall quality assessment
            - Production readiness statement

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         TOOLS TO USE:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         Required Tools:
         â–¡ File Reader: Read all source code files
         â–¡ Syntax Validator: Validate code syntax for each language
         â–¡ Test Generator: Create comprehensive test files
         â–¡ Test Runner: Execute test suites
         â–¡ Code Formatter: Format code (Black, Prettier, etc.)
         â–¡ Linter: Check code style (Flake8, ESLint, etc.)
         â–¡ Type Checker: Verify types (mypy, tsc, etc.)
         â–¡ Code Executor: Run main program
         â–¡ Dependency Installer: Install test dependencies
         â–¡ Coverage Reporter: Generate coverage reports

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         LANGUAGE-SPECIFIC TESTING COMMANDS:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         Python:
         Tests: pytest tests/ -v --cov={project_dir} --cov-report=html
         Format: black {project_dir}
         Lint: flake8 {project_dir}
         Type: mypy {project_dir}
         Security: safety check

         JavaScript/TypeScript:
         Tests: npm test -- --coverage
         Format: prettier --write .
         Lint: eslint src/
         Type: tsc --noEmit
         Security: npm audit

         Java:
         Tests: mvn test  OR  ./gradlew test
         Format: mvn spotless:apply
         Lint: mvn checkstyle:check
         Security: mvn dependency-check:check

         C#:
         Tests: dotnet test --collect:"XPlat Code Coverage"
         Format: dotnet format
         Lint: dotnet build /p:EnforceCodeStyleInBuild=true
         Security: dotnet list package --vulnerable

         Go:
         Tests: go test ./... -v -cover
         Format: go fmt ./...
         Lint: golangci-lint run
         Security: govulncheck ./...

         Rust:
         Tests: cargo test
         Format: cargo fmt
         Lint: cargo clippy
         Security: cargo audit

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         CRITICAL QUALITY GATES:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         The project MUST meet these criteria to be approved:

         âœ… MANDATORY (Must Pass):
         â–¡ No syntax errors
         â–¡ All tests pass (100% pass rate)
         â–¡ No critical security vulnerabilities
         â–¡ No hardcoded secrets or credentials
         â–¡ Code builds/compiles successfully
         â–¡ Main program executes without errors
         â–¡ README installation instructions work

         âš ï¸ STRONGLY RECOMMENDED (Should Pass):
         â–¡ Test coverage â‰¥ 80%
         â–¡ No major linting errors
         â–¡ All public APIs documented
         â–¡ No memory leaks detected
         â–¡ Response times within acceptable limits
         â–¡ No high or critical dependency vulnerabilities

         ğŸ¯ NICE TO HAVE (Bonus):
         â–¡ Test coverage â‰¥ 90%
         â–¡ Zero linting warnings
         â–¡ Cyclomatic complexity < 10 for all functions
         â–¡ Performance benchmarks documented
         â–¡ Accessibility compliance (for UI)

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         EXPECTED DELIVERABLES:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         1. Complete test suite in tests/ or __tests__/ directory
         2. TEST_REPORT.md with comprehensive results
         3. Coverage report (HTML format if available)
         4. Fixed/formatted code (if formatting issues found)
         5. List of identified issues with severity levels
         6. Recommendations for improvements
         7. Security scan results
         8. Performance analysis (if applicable)
         9. Final approval/rejection decision with justification

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         SUCCESS CRITERIA:
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

         The project is considered PRODUCTION-READY if:
         âœ… All mandatory quality gates pass
         âœ… All tests execute and pass
         âœ… Code is properly formatted and linted
         âœ… Documentation is complete and accurate
         âœ… No critical security issues
         âœ… Application runs without errors
         âœ… Test coverage meets minimum threshold
         âœ… Performance is acceptable for intended use case

         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         BEGIN COMPREHENSIVE TESTING AND QUALITY ASSURANCE NOW!
         â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         """,
         agent=agent,
         context=context_tasks,
         expected_output="""Complete testing report including:
                           - Test file creation summary
                           - Test execution results
                           - Code formatting results
                           - Linting results
                           - Main program execution output
                           - List of any issues found
                           - Overall quality assessment
                           - TEST_REPORT.md file"""
    )